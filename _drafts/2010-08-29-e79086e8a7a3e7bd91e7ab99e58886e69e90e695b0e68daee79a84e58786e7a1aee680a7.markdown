---
author: cloga0216
comments: true
date: 2010-08-29 04:24:03+00:00
layout: post
slug: '%e7%90%86%e8%a7%a3%e7%bd%91%e7%ab%99%e5%88%86%e6%9e%90%e6%95%b0%e6%8d%ae%e7%9a%84%e5%87%86%e7%a1%ae%e6%80%a7'
title: 理解网站分析数据的准确性
wordpress_id: 119
tags:
- Google Analytics
- web metrics
---

当谈到网站效果的标准时，网站分析是关键。但是，这种信息只有在你避免了与收集数据相关的一些常见错误时，才是准确的，特别是与多种来源比较时。

偏偏，太多的企业对网站分析报告有肤浅的理解。毕竟，获得数字并不难。严酷的事实是网站分析的数据永远也不可能是百分之百准确的，甚至测量误差线也将很困难。

那么，重点是什么？

尽管有缺陷，但是基本上，误差线在每周或甚至每月都保持相对稳定。甚至比较年与年的行为也是安全的，只要在技术上或终端用户行为没有巨大的变化。只要你使用相同的标准，访问者数的趋势将是准确的。例如，网站分析数据能反映以下的模式：

·30%的流量来自搜索引擎

·50%的流量来到X.html页面

·上周我们从email广告活动增加了20%的订阅转化

·三月里网站目录页的跳出率减少了10%

通过这些指标，营销人员和网站管理员能够确定特定营销活动的直接影响。详细程度是关键。例如，你能确定增加PPC广告——单一搜索引擎的一系列关键字，能否增加这段时期内的投资回报率。只要你能将不准确性控制在最小，那么网站分析工具对测量你的线上业务的访问者流量是有效的。

**数据点的冲突是常见的。**** **

英国的对800个企业的调查表明将近三分之二（63%）的受访者表示，他们遇到过来自不同网络数据测量的信息冲突。

（“网络测量和策略报告2009”，Econsultancy.com，2009年六月）

接下来，我将详细讨论为什么会出现这些不准确，以使你能正确看待这一信息。其目的是使你能对分析数据达到一个可接受的准确性水平。回想一下表2.1，两种收集网站访问者数据的主要方法——日志文件和页面标签——都有局限性。


#### 影响日志文件访问者数据准确性的问题


日志文件跟踪通常在服务器上默认安装。可能因为这一原因，系统管理员很少考虑其他的跟踪方法。


#### 动态分配的IP地址


一般来说，日志文件法通过将相同的IP地址和浏览器签名的所有点击归为一个人，来跟踪访问者的会话。当网络服务服务提供商在会话过程中分配不同的IP地址时，会出现问题。总部设在美国的comScore的一项研究（http://www.comscore.com/Press_Events/Presentations_Whitepapers/2007/Cookie_Deletion_Whitepaper）表明，一台典型的家用PC每个月平均有10.5个不同的IP地址。这些访问者将被日志文件分析软件计算为10个独立访问者。由于每个网络用户都有相同的浏览器签名（当前的IE），所以，这个问题将更加严重。结果，访问者数量被极大的高估。cookies的使用可以克服这一局限性。


#### 客户端缓存页面


客户端缓存指存储在访问者电脑上的先前访问页面。在这种情况下，再一次访问相同页面导致这一页面由访问者的电脑提供，因此，这一次访问没有被记录在服务器中。

服务器端缓存来自于网络加速技术，这种技术缓存网站的一个副本，并从他们的服务器提供这一副本以加速传输，这意味着所有随后的网站请求来自缓存而不是网站本身，导致了跟踪信息的丢失。现在，大部分网站都以某种方式缓存以改善性能。例如，在[http://en.wikipedia.org/wiki/Cache](http://en.wikipedia.org/wiki/Cache)看一下维基百科关于缓存的解释。


#### 计算机器人


机器人，也被称为蜘蛛或网络爬虫，最常被搜索引擎用来抓取和索引页面。但是，也存在其他监测服务器性能的机器人——运行时间、下载速度等等，还有的进行页面分析，包括比价、email搜集和竞争性研究等等。这些影响网站分析，因为日志文件法也包括机器人在你网站上的活动，尽管它们并不是真正的访问者。当计算访问者数量时，机器人占网站综合浏览量的很大比例。遗憾的是，很难完全过滤这些，因为有数千自制的、不知名的机器人存在。因为这个原因，日志分析法可能高估访问者数量，在大多数情况下，这是很严重的。 
