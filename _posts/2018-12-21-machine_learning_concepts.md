---
title: "机器学习概念"
author: "cloga"
comments: yes
layout: post
slug: machine_learning_concepts
tags:
- machine learning
- 他山之石
categories: machine learning
---

机器学习（ML）可以帮助你使用历史数据来作出更好的商业决策。机器学习算法发现数据中的模式，并且用这些发现构建数学模型。你可以用这些模型对未来的数据进行预测。例如，一个机器学习模型的可能应用可以根据消费者历史的行为预测他购买特定商品的可能性。

## 使用机器学习解决商业问题

你可以在带有真实答案的已有样例的问题上应用机器学习。例如，如果你想使用机器学习来预测一封email是否是垃圾邮件，你可以收集被正确标记为垃圾邮件或非垃圾邮件的样例。接下来你可以使用机器学习在这些email样例上进行归纳，以便预测新email是不是垃圾邮件。这种从带有标记的真实答案的数据上进行学习的方法被称为监督式机器学习。

你可以在这些特定的机器学习任务上使用监督式机器学习：二分类（从两个潜在结果中预测一个），多分类（从两个以上的结果中预测一个）以及回归（预测一个数值）。

二分类问题里的例子有：

- 客户会不会买这个产品？
- 这封邮件是不是垃圾邮件？
- 这个产品是书还是农产品？
- 这个评论是消费者写的还是机器人？

多分类问题的例子有：

- 这个产品是书、电影还是衣服？
- 这个电影是浪漫戏剧、纪录片或惊悚片？
- 这个消费者最关系哪类产品？

回归问题的例子有：

- 明天北京的天气是多少？
- 这个产品的未来销量是多少？
- 这个消费者在多少天后停止使用这个应用？
- 这个房子值多少钱？

## 什么时候用机器学习

牢记机器学习不是适用于所有问题的解决方案，这很重要。在许多情况下，不需要使用机器学习技术就可以创建强健的解决方案。例如，如果你可以通过简单的规则、计算来决定目标值，或者预先定义的步骤可以被程序化，而不需要任何数据驱动的学习，那么你不需要机器学习。

在以下场景使用机器学习：

- *无法编码规则*：需要人类任务（例如识别一个email是不是垃圾邮件）不能使用简单的（决定主义）、基于规则的解决方案很好的解决。大量的因素会影响答案。当规则依赖太多的因素并且许多规则重叠或需要精细的调节时，很快就会变得很难由人类来准确编码规则。你可以使用机器学习来有效的解决这个问题。
- *无法扩展*：人工识别几百个email判断是不是垃圾邮件是可行的。但是，当面对几百万email时，这个任务就变得单调乏味了。机器学习方案可以有效的处理大规模的任务。

## 构建一个机器学习应用

构建一个机器学习应用是一个包含一系列步骤的迭代过程。要构建一个机器学习应用，遵循下列通用的步骤：

1. 以观察到什么和你想要模型预测什么答案来解构核心的机器学习问题
2. 收集、清理准备数据，以便使数据适于机器模型训练算法来消费。对数据进行可视化和分析，进行健康检查来判断数据质量和理解数据。
3. 通常，原始数据（输入变量）和答案（目标）都不是用可以用于训练高预测性模型的方式来表征。因此，你通常应该从原始变量中尝试构建更有预测性的输入表征或特征。
4. 将产生的特征喂给学习算法来构建模型，并且用构建模型以外的保留数据来评估模型的质量。
5. 使用模型对新数据实例来产生目标答案的预测。

### 表征问题

机器学习的第一步是决定你要预测什么，这被称为标签或者目标答案。想象这个场景，你想要生产产品，但是你决定根据每个产品的潜在销量来制造每个产品。在这个场景下，你想要预测每个产品将被购买多少次（预测销量）。使用机器学习来定义这个问题可以有多种方式。选择如何定义这个问题，取决于你的用例或者商业需求。

你是想要预测消费者将要在每个产品上购买的次数（这个场景下，目标是数值型的，你正在求解一个回归问题）？或者你是想要预测哪个产品将获得10个以上的购买（这个场景下，目标是二分的，你正在求解一个二分类问题）？

避免过于复杂化问题这很重要，用最简单的方法来满足你的需求。但是，避免丢失信息也很重套，特别是在历史答案中的信息。这里，将过去的实际销量转换为二分变量“大于10” VS “小于10”可能丢失有价值的信息。花费时间来决定那个目标对你的预测最敏感，将避免你构建一个不能回答问题的模型。

### 收集标记的数据

机器学习问题始于数据--最好是，已经知道目标答案的很多数据（例子或者观察）。已经知道目标答案的数据被称为*带有标记的数据*。在有监督机器学习中，算法从我们提供的标记样例中进行自我学习。

数据中的每个样例/观察必须包含两个元素：

- 目标 - 你想要预测的答案。你为机器学习算法提供被标记为带有目标的数据（正确答案）来进行学习。接下来，使用训练的机器学习模型来在你并不知道答案的数据上预测这个答案。
- 变量/特征 - 样本的属性，可以用于识别可以预测目标值的模式。

例如，对于email分类问题，目标是个标记email是否是垃圾邮件的标签。变量的例子是email的发送者、email的文本正文、文件的主题行、email的发送时间以及发信人与收信人之前是否有书信往来。

通常，数据不是方便的以标记的方式来获得。收集和准备变量和目标通常是解决机器学习问题的最重要步骤。样本数据应该是你将要使用模型来作出预测的数据的典型代表。例如，如果你想要预测email是不是垃圾邮件，你需要同时收集正例（垃圾邮件）和负例（非垃圾邮件），以便机器学习算法可以找到区分两类email的模式。

当你有了标记的数据，你需要将它转换为算法或者软件可以接受的格式。例如，你可能需要将数据转换为CSV格式，每个样本构成CSV文件的一行，每一类包含一个输入变量，其中一类包含目标答案。

### 分析数据

在将数据丢给机器学习算法前，良好的习惯是检查一下数据来识别问题并且获得对于正在使用的数据的见解。模型的预测力将会和你喂给他的数据一样好。

当分析数据时，需要将以下观点记在脑中：

- 变量和目标数据总览 - 理解变量的值以及哪些值在数据占支配地位很重要。你可以和一个与要研究问题利益相关的专家一起来进行数据总览。问一下你自己或者利益相关的专家：数据符合期望吗？是否看起来有数据收集问题？是否目标的一个类别比其他类别多很多？是否缺失值或无效数据多于预期？
- 变量-目标的相关 - 了解每个变量与目标类别的相关是很有用的，因为高相关意味着变量和目标类别之间有关系。通常来说，你想要包含有高相关的变量，因为，他们有高预测力（信号），不包含那些低相关的变量，因为他们可能低相关。

### 特征工程（处理）

通过数据总览和可视化了解数据之后，你会想要进一步转换你的变量让他们更有意义。这被称为*特征处理*。例如，假如有一些变量捕捉到事件发生的日期和事件。这个日期和时间不会再次出现，因为对于预测目标不会有任何帮助。因此，如果这个变量被转化为代表一天中的小时，星期以及月份等特征，如果这些事件倾向于在特定小时，星期或者月份发生，那么这些变量将会非常有用。这种构成更泛化的数据点来进行学习的特征处理可以为预测模型提供显著的改善。

通用特征处理的其他例子：

- 用更有意义的值（例如，你知道缺失的产品类别变量其实是书，那么你可以将所有产品类别中的缺失值替换为书）替换缺失或者无效的数据。增补缺失值的常见策略是将缺失值替换为平均数或中位数。选择替换缺失值的策略前，理解你的数据很重要。
- 构造一个特征与另一个特征的笛卡尔积。例如，如果你有两个变量，例如人口密度（城市、郊区、农村）和省份（北京、上海、广州），那么由这两个变量的笛卡尔积构成的特征中很可能有有用的信息（城市\_北京，郊区\_北京，农村\_北京，城市\_上海，郊区\_上海，农村\_上海，城市\_广州，郊区\_广州，农村\_广州）。
- 非线性变换例如将数值型变量分箱到类别中。在许多情况下，数值特征与变量的关系不是线性的（特征值与目标数值不是单调递增或者单调递减）。这种情况下，有效的方式是将数值特征分箱为代表不同数值特征范围的类别特征。每个类别特征（箱）可以接下来各自独自与目标进行线性关系的建模。例如，假如你知道连续的数值特征年龄与买书的可能性不是线性的。你可以将年龄分箱成类别特征，这可能更准确捕捉与目标的关系。数值变量的最佳分箱数取决于变量的特征以及它与目标的关系，最好通过实验来判断。
- 领域相关的特征（即，长宽高是独立的变量，你可以创建一个新变量：体积，其值为这三个变量的乘积）。
- 变量相关的特征。一些变量类型例如文本特征，这些特征可以捕捉网页结构，或句子的结构有通用的处理方式来帮助抽取结构或背景。例如，从“the fox jumped over the fence”文本中构建n-grams可以被表征为*unigrams*：the，fox，jumped，over，fence或*bigrams*：the fox，fox jumped，jumped over，over the，the fence。

包含更相关的特征有助于改进预测能力。很明显，不可能常常预先知道哪些特征有“信号”或预测影响力。因此，最好是包含可能对目标标签有可能相关的所有特征，并且让模型训练算法挑选最相关的特征。

### 数据拆分为训练和评估数据

机器学习的基本目标是对用于训练模型的数据实例进行归纳推理。我们想要评估一下模型在没有训练过的数据上的模式泛化质量。但是，因为未来的实例的目标值是未知的，我们此时无法检查我们在未来实例上预测准确性，我们需要使用一些我们已知答案的数据作为未来数据的代表。用训练的数据来评估模型是没用的，因为，这是奖励模型可以“记住”训练数据，而不是对训练数据进行推理。

一个通用的策略是使用所有的标记好的数据，将它拆分为训练和评估子集，通常70-80%是训练，20-30%是评估。机器学习系统使用训练数据来训练模型，了解模式，使用评估数据评估训练好的模型预测质量。机器学习系统通过多种指标来对比评估数据集的预测与真实值（被称为groud truth），评估预测效果。通常，你使用在预测集上表现“最佳”的模型来对你所不知道目标答案的未来实例进行预测。

### 训练模型

现在，你已经准备好用训练数据提供机器学习算法（即*学习算法*）。算法将从训练数据中学习变量和目标的映射关系，并且将输出捕捉到这些关系的模型。接下来，这个机器学习模型将用于从未知目标答案的新数据上进行预测。

#### 线性模型

有海量的机器学习算法可选。线性模型是指模型是特征的线性组合。基于训练数据，训练过程计算每个特征的权重来构成模型，模型用于预测或者估计目标值。例如，如果你的目标是一个顾客会购买的保险金额，并且你的变量是年龄、收入简单的线性模型是：

预测目标 = 0.2 + 5 * 年量 + 0.0003 * 收入

#### 算法学习

算法学习的目标是学习模型的权重。权重描述了模型学到的模式影响数据实际关系的可能性。算法学习包含损失函数和优化技术。损失是当机器学习算法提供的预测目标与真实目标不匹配时的惩罚。损失函数将这个惩罚量化为一个值。优化技术寻找损失最小化。

随机梯度下降（SGD）是一种常见的优化方式。SGD让训练数据顺序通过，每次迭代时，每次每个实例更新特征权重，以便达到最小化损失的最优权重。

### 参数训练

机器学习算法接受参数，称为超参数或训练参数，允许你控制结果模型的质量。通常机器学习算法会有静态的默认超参数。尽管默认的超参数设置通常可以产出有用的模型，你也可以通过调整超参数的值来改善模型的预测效果。下面的部分描述学习线性模型的通用超参数。

#### 学习率

学习率是在随机梯度下降（SGD）算法中使用的固定值。学习率影响算法达到（收敛）最佳权重的速度。看到每个数据样本之后，SGD算法更新线性模型的权重。学习率控制更新的大小。过大的学习率可能导致无法获得最佳的权重。过小的值导致算法需要过多迭代次数来达到最佳的权重。

#### 模型大小

如果有很多输入特征，数据中的可能模式数会导致大模型。大模型有实现上的影响，例如，在训练时或生成预测时需要更多的RAM来保存模型。你可以通过使用L1正则来减少模型大小，或者指定最大大小来限定模型大小。注意如果模型大小缩小的太多，会减弱模型预测能力。

#### 迭代次数

SGD算法在训练数据上进行顺序迭代。*迭代次数*参数控制训练数据在算法上的迭代次数。更多的迭代次数导致一个模型更好的适应数据（如果学习率不是太大），但是，随着迭代次数的增加，优势会逐渐消失。对于小数据集，你可以显著增加迭代，这会这允许学习算法更有效的贴近数据。对于非常大的数据集，一次迭代可能就足够了。

#### 数据重组（Shuffling）

使用SGD算法必须要重组数据，因为，SGD算法回收训练集中行顺序的影响。重组训练数据结果导致一个更好的机器学习模型因为它避免SGD算法避免在先看到的数据上是优化的，而不是在全部的数据上（局部最优）。重组混合数据顺序，这样SGD算法不会持续遇到一类数据的太多次观察。如果算法只观察到一类数据来持续更新权重，算法可能无法对新数据类型提供正确的模型权重，因此这个更新太大了。另外，当数据不是随机出现，对算法来说要很快找到针对所有数据类型最优的权重会比较困难。重组训练数据帮助算法更快收敛到最优解。

例如，假如你要训练一个机器学习模型来预测产品类别，并且你的训练数据包含电影、玩具、视频游戏产品类。如果，你根据产品类别列排序数据，那么算法看到的数据是按照产品类别的字母顺序。算法先看到你的所有电影数据，机器学习模型开始学习电影的模式。接着，当你们的模型遇到玩具的数据，算法的每次更新将把模型调整为玩具产品类别，即使这些更新会降权适合电影的模式。这种从电影到玩具类型的突然切换会生成一个无法准确预测产品类型的模型。

#### 正则化

正则化可以通过惩罚，帮助避免线性模型在训练数据样例上过拟合（即记忆模型都不是归纳模型）。L1正则化会通过将在其他方面有很小权重的特征置为0，减少模型中使用的特征的效果。作为结果，L1正则化会产生稀疏数据，并且减少模型的噪音。L2正则化产生一个更小的总体权重值，并且当输入特征间有高相关时会稳定权重。非常大的正则化的值会导致所有特征都有0权重，造成模型学不到任何模式。

### 评估模型准确性

机器学习模型的目标是学习在未见过的数据上很好归纳的模式，而不仅仅是记忆在训练中显示的数据。一旦你有个模型，测试模型在非模型训练中使用的未见过的数据上的表现很重要。要做到这点，你需要使用模型在验证集（保留的数据）上预测答案，然后比较预测的结果与实际的答案（真实情况）。

在机器学习中可以使用很多指标来测量模型的预测准确性。准确率指标的选择取决于具体的机器学习任务。检查这些指标来决定模型是否在正常运行很重要。

#### 二分类

二分类算法的实际输出是预测分数。这个分数表明对于给定的观察属于积极类的确定性。要决定一个观察是否应该被分类为积极或消极，作为这个分数的消费方，你可以通过选择不同的分类阈值（切分点）来解释分数，并且与这个分数比较。任何比阈值分数高的观察都将被预测为正类而比阈值低的分数将被预测为负类。

![二分类模型的分数分布](https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image2.png)

图1：二分类模型的分数分布

现在预测会根据实际答案和预测答案被分为四组：正确的正例（真正例）、正确的负例（真负例）、错误的正例（负正例）、错误的负例（负负例）。

二分类准确率给出了两类正确预测和两类错误数量指标。典型的指标是准确率（ACC）、精确率、召回率、误报率、F1值。每个指标测量了预测模型一个方面。准确（ACC）测量了正确预测的比例。精确测量了真实的正例在所有的预测为正例的样本中的比例。召回率测量了有多少真实正例被预测为正例。F1值是精确和召回的调和平均数。

AUC是另一类指标。它测量了模型对正例比负例预测更高的分数的能力。因为AUC与选择阈限无关，不需要选择一个阈值就可以从AUC值了解模型的预测性能。

根据业务问题的不同，你可能对在这些指标的一个特定方面表现好的模型更感兴趣。例如，两个商业应用对机器学习模型有差异很大的需求：

一个应用可能需要对正例预测真的是正例非常确信（高精确）并且可以忍受将一些正例错误分类为负例（中等召回）。

另一个应用可能需要预测尽可能多的正例（高召回）并且可以接受一些负例为错误分类为正例（中等精确）。

在机器学习中，观测获得的预测范围在[0,1]。作出分类0，1决策的分数阈值默认是0.5。你可以观察影响并选择一个与业务想匹配的阈值。

#### 多分类

与二分类问题的流程不同，你不需要选择作出预测的分数阈值。预测答案是有最高预测分数的类（即标签）。在一些情况下，只有等预测了一个很高的分值你才可能使用这个预测答案。在这种情况下，你可以选择一个你可以接受预测答案的阈值。

多分类与二分类使用的指标是相同的。每一类的指标是通过将所有其他类都分组为第二个分类来转换为二分类问题。接着所有类别二分类指标的平均来获得一个macro平均值（将每个类同等看待）或者加权平均（根据类别频率加权）指标。

![多分类模型的混淆矩阵](https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image3.png)

图2:多分类模型的混淆矩阵

检查多分类问题的*混淆矩阵*很有帮助。混淆矩阵是显示每一类的评估数据与正确预测和错误预测数量或比例的表格。

#### 回归

对于回归任务，典型的准确率指标是标准误差（RMSE）和平均绝对百分比误差（MAPE）。这些指标测量了预测的数值目标与实际的数值指标（真实情况）间的距离。

![](https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image4.png)

图三：回归模型的残差分布

通常的操作是查看回归问题的*残差*。观察的残差是评估数据与真实目标和预测目标之间的差异。残差代表模型无法预测目标的部分。正残差代表，模型低估了目标（真实目标比预测目标大）。负残差表示高估（真实目标比预测目标小）。评估数据的残差直方图的分布为钟形并且中心点为0表明模型以随机的方式出错，并没有系统性的高估或低估目标值的特定范围。如果残差并没有构成以0为中心的钟形，模型有一些结构性预测错误。为模型添加更多的变量有助于帮助模型捕捉现有模型没有捕捉到模式。

### 改善模型准确率

获得匹配预期的机器学习模型通常包含迭代这个机器学习流程，并且长庚一些变化。你不可能在第一次迭代就获得很有预测力的模型，或者你应该想要改善模型来获得更好的预测。要改善效果，你应该迭代以下步骤：

1. 收集数据：增加训练集的数量
2. 特征处理：添加更多的变量和更好的特征处理
3. 模型参数调优：考虑更多的学习算法的训练参数

#### 模型拟合：欠拟合 VS 过拟合

理解模型拟合对于理解交叉的模型正确的根本原因很重要。这个理解将指导你采取改正的步骤。我们可以通过查看训练数据和评估数据的预测误差来判断预测模型是过拟合还是欠拟合。

![欠拟合、平衡、过拟合](https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image5.png)

当模型在训练数据上表现较差时，模型*欠拟合*训练数据。这是因为模型无法捕捉数据实例（通常称为X）和目标值之间的关系（通常称为Y）。当模型在训练数据上表现很好，但是在评估数据上表现很差，那么模型*过拟合*的训练数据。这是因为模型记住了看到的数据，而无法推广到没有见过的样例。

训练数据上的糟糕表现可能是因为模型过于简单（输入特征不够丰富）无法描述目标。增加模型的灵活性可以改善效果。要增加模型灵活性，尝试如下方法：

- 添加新的领域相关的特征和更多的特征笛卡尔积，并且改变特征处理使用的类型（例如增加n-grams的大小）
- 减少正则化使用的数量

如果模型过拟合了训练数据，就需要采取动作减少模型的灵活性。要减少模型的灵活性，尝试如下步骤：

- 特征选择：考虑使用更少的特征组合，减少n-grams的大小，增叫数值特征分箱的数量。
- 增加正则化使用的数量。

训练数据和测试数据的准确性会比较差，因为学习算法没有足够的数据。你可以如下方式改善性能：

- 增加训练数据样本的数量
- 增加在现有训练数据上的迭代次数

### 使用模型来进行预测

现在你有了一个表现良好的机器学习模型，你可以用它来进行预测。通常有多种使用模型进行预测的方式：

#### 批量预测

当你想要针对一组观察一次产生全部的预测，然后基于观察的一定比例或数据采取行动时，批量预测很有用。通常，对于这类应用不需要一个低延迟。例如，当你想要决定哪些消费者应该被作为一个产品广告活动的受众时，你将需要获得所有消费者的预测分数，排序模型预测结果来识别最可能购买的消费者，然后目标将是最可能购买的5%的用户。

#### 在线预测

在线预测场景适用于当你想要在1对1的基础上，在低延迟的环境中，每个样本独立于其他样本产生预测时。例如，你可能想要对特定的交易是不是欺诈交易立刻作出决策。

### 在新数据上重新训练模型

模型要准确预测，训练的模型与预测模型的分布必须一致。因为数据分布会随着时间发生变化，部署模型不是一次性的事情而是一个持续的过程。最佳实践是持续关注输入数据，如果发现数据分布严重偏离原始训练数据的分布。如果监控数据发现数据分布变化是经常发生的，那么更简单的策略是周期性的训练模型，例如，每天，每月。



